topics:
1:numpy


==================================================================================================
1:numpy-
-NumPy: short for Numerical Python
provides an efficient interface to store and operate on dense data(many different pieces of the required information on a specific kind of a subject, no matter whatever the subject happens to be) buffers
NumPy arrays form the core of nearly the entire ecosystem of data science tools in Python, so time spent learning to use NumPy effectively will be valuable no matter what aspect of data science interests you.


==================================================================================================

doubts: why corresponding environment is not shown as active even if we launch that environment from wsl
-You can manually specify the path to the conda executable to use for activation (version 4.4+). To do so, open the Command Palette (Ctrl+Shift+P) and enter Preferences: Open User Settings. Then set python.condaPath, which is in the Python extension section of User Settings, with the appropriate path.

-we can have different environments in conda, and each environment can have different packages installed.
-to activate a particular base we have to use - conda activate <environment name>
-similarly to deactivate a particular base we have to use - conda deactivate <environment name>
-We will name the environment snowflakes and install the package BioPython. At the Anaconda Prompt or in your terminal window, type the following:
	conda create --name snowflakes biopython
-to see the list of info's type:
	conda info --envs
		(snowflakes) saivinil_pratap@TIGER02143:~$ conda info --envs
			# conda environments:
			#
			base                     /home/saivinil_pratap/miniconda3
			snowflakes            *  /home/saivinil_pratap/miniconda3/envs/snowflakes
	the * shows that the snowflakes is the current active environment,alternatively you can confirm this by seeing the name that is in the brackets above when we try to execute the command "conda info --envs"
-if you want to move back to base environment, you can simply type-
	conda activate
		this will move the environment to default environment which is base.
-when you create a new environment conda uses the same python version which is used to  download and install anaconda, if you want to create a new environment with different python version, then you have to use the following command:
	conda create --name <version name> python=<version>
	ex: conda create --name MLproj-env python=3.7
-if you want to search for a package in ANACONDA REPOSITORY
	ex: conda search *eauti* (it supports wild card entries and it will check the repository and lists the package that has "eauti" inside it )
-pipenv run black <python file path>
black is a package that will try to format code according to the python standards
this command will try to make the code structured by making considerable changes that will make the code look neat eloquent,elagant and easy to understand	(to do this you have to install pipenv and black)
-pipenv run isort <python file path>
isort is a package in python,isort helps to sort and format imports in your Python code. Black also formats imports, but in a different way from isort’s defaults which leads to conflicting changes.
-flake8:
it is a code linter in python, a code linter is basically a program that will check your code and gives feedback.it can detect issues in the program and suggest solutions to resolve them. you can run the linter anytime to let the code have good standards
-if you want to debug python code in visual studio: place the cursor on the line where you want to add a debug point and press f9
-plots dont work with wsl (version 1) configuration of vscode, but you can get plots by right clicking on them and then running it in interactive mode.
-when you are using virtual environments in vs code then, in the terminal you have to activate corresponding environment and then press ctrl+shigt+p and select the same interpreter
-you have used some commands or functions and terminated session, if you want to get them back you can use  the reverse-i-search which can be implemented by shortcut ctrl+r is useful in linux related systems. commands/functions that are used before and after terminating the session can be recalled
-When you are working with a virtual environment and you had installed specific packages to cover all the needs and you're ready to deploy the application to other computers, you can create a requirements.txt file with the command pip freeze > requirements.txt (pip3 on macOS/Linux). The requirements file describes the packages you've installed in your virtual environment. With only this file, you or other developers can restore those packages using pip install -r requirements.txt (or, again, pip3 on macOS/Linux). By using a requirements file, you need not commit the virtual environment itself to source control.
-If you create a new conda environment while VS Code is running, use the Reload Window command to refresh the environment list shown with Python: Select Interpreter; otherwise you may not see the environment there. It might take a short time to appear; if you don't see it at first, wait 15 seconds then try using the command again.
-if you want to launch vs code for a particular folder while you are using WSL, then just navigate to the folder in linux and then give the command "code .", then you can open that folder in vs code without any hassle, if you just want to load vs code without any directory (cwd in linux) being prioritized just enter "code"
-if you are having a lot of text(as command which you dont want to execute) in terminal and if you want to remove, press ctrl+u
-if you are working from vs code using python installation and you want to activate the command code, then you have to type "shell command:code install code command in the path" in the command palette and then select it, so from now you will have the option to type "code" from the cmd(command prompt) and then launch it in vscode
-to select text vertically in vs code you have to press shift+alt and then select
-Select and activate an environment#
	By default, the Python extension looks for and uses the first Python interpreter it finds in the system path. To select a specific environment, use the Python: Select Interpreter command from the Command Palette (Ctrl+Shift+P).
	The Python: Select Interpreter command displays a list of available global environments, conda environments, and virtual environments. (See the Where the extension looks for environments section for details, including the distinctions between these types of environments.) The following image, for example, shows several Anaconda and CPython installations along with a conda environment and a virtual environment (env) that's located within the workspace folder:
-we can also open ipynb files, all we have to do is try opening the folder that already has ipynb files and it will automatically configure that and open it as a notebook
-in vscode-to shift control from editor to terminal, you can create a shortcut by going to command palette(ctrl+shift+p) and search "focus terminal" and add custom shortcut, similarly to shift focus back to editor- Ctrl + E , Enter.
	else you can simply press ctrl+~ to minimize or activate terminal(current one if exists, or a new one if it does not exists)
-if you want to navigate within the filesystem and then press ctrl+e and then type the starting words of the file and vscode will start giving suggestions, press enter (when you see the file you want to navigate to) and you just will be moved to that file. Now you want to go to a particular variable type "@" (after pressing ctrl+e because this will put preference of variables first and methods later) and then start typing the variable name, it will try to fetch the results, if you want to search for methods type "@:" (after pressing ctrl+e,then it will prefer listing methods first, and when you start typing some letters it will try to filter accordingly)
-code completion is a useful feature and at any point, if you have to use suggestions to perform autocompletion at anypoint, simply press ctrl+space (if it does not work, check for the shortcut "suggest" and it will be understandable from that point,to see what should be done)
-suppose you have a method/ variable declared somewhere else and you are using it in the current line a and you want to edit the variable/method, then by pressing alt+f12 it is feasible to edit the method/variable as it will show a popup of its declaration in current line
-suppose you want to see all the function definitions, go to function declaration and click on anywhere in the name of the function, press shift+f12, in the popup that appears, in the right side you can see the declarations of the function, and clicking on any of it will move you to the that part of file
-if you want to test the methods, install pytest and then it will search for python files that start with test, and in the files that start with test and then it will automatically display them in testing sidebar, you can run them, debug them all or one by one
-pipx
we might have different packages installed in different environments, and if you want some package which is commonly used by all environments (maybe a package which deals with code formatting- black8 or codelinter which is used for linitng), we can install them using pipx so that the packages are installed in an isolated environment which can be used for further need.
-a python package must have __init__.py file(mostly it is empty, it is called a package only if it has __init__.py file), It is a collection of python modules. a python module is a single python file(with code no lengthier than 500 lines of code including comments). The different modules in the package are imported in a similar manner as plain modules, but with a special behavior for the __init__.py file, which is used to gather all PACKAGE-WIDE DEFINITIONS.
A commonly seen issue is adding too much code to __init__.py files. When the project complexity grows, there may be sub-packages and sub-sub-packages in a deep directory structure. In this case, importing a single item from a sub-sub-package will require executing all __init__.py files met while traversing the tree.
Leaving an __init__.py file empty is considered normal and even good practice, if the package’s modules and sub-packages do not need to share any code.
-package names are lower case with an underscore to seperate words, and are always singular
-module names are lowercase with an underscore to seperate words
-Lines must not exceed 79 characters in length
-imports are always placed after module comments and doc string(which are placed at the starting of the file), and placed above the module globals and constants
	Imports should be grouped in the following order:
		standard library imports
		related third party imports
		local application/library specific imports
	You should put a blank line between each group of imports
-instead of using from <packagename> import *, we can use from <packagename> import <module1>,<module2>... and so on as the first declaration gets all the methods as identifiers which is not a expected behaviour, so the second mode of declaration will give the better approach because we will list only the required identifiers.
-using comments to let the flow understand is a good approach, but comments that are not up to date with the code changes is worse than having no comments at all, updating comments along with the code is the only better approach you can have with comments, comments should be complete sentences, it should begin with a capital letter, unless starts with an identifiers.
-BLOCK COMMENTS: comments that consist of one or more paragraph, each paragraph is built with complete sentences, each statement ends with a period, and after each period you should use double spaces before you start another sentence.
-The first line of a docstring should be a one line summary. As noted in the example below.  Follow that line with a blank line, and then continue with a description or examples as appropriate.  Examples are called out on a new line, indented an additional four spaces, and begin with >>>. This convention will produce nicely formated examples in the resulting html pages, so do not hesitate to use it.  Conventions for writing good docstrings are found in PEP 257
-Block comments generally apply to some (or all) code that follows them, and are indented to the same level as that code.  Each line of a block comment starts with a # and a single space (unless it is indented text inside the comment). Paragraphs inside a block comment are separated by a line.
-An inline comment is a comment on the same line as a statement. Inline comments should be used SPARINGLY.  Inline comments should be separated by at least two spaces from the statement.  They should start with a # and a single space. Remember to use SPARINGLY, although sometimes, they can be useful
ex:s = s + 1    # Compensate for the border.
-class definitions must contain doc string, class name should be CamelCase
-'Special' methods (ie. those methods starting and ending in double underscores) should usually be grouped at the start of the class definition.  The exception is when the class is implementing the interface of a built-in type such as 'list' or 'dict'.  In that case the special methods on the interface follow the rules listed below.
-a protected variable or a non public variable starts with single underscore and is intended for only use of current class and the classes that derive the current class
-a private attribute is preceeded by a double underscore, they can be used only inside the class.
-functions that does not return also should be delimited by a return (i.e, a function should have an empty return at the end, even if it does not return any value)
 Methods should be grouped and ordered as follows:- 1) 'object interface (ie. special methods). 2) Methods offered on inherited or delegated interfaces of the class. 3) Methods offered on the primary public interface of the class. 4) Non-public methods 5) private methods
-A method definition must contain a docstring. Method names are lowercase with an underscore used to separate each word. The ONLY exception to this is if you are inherting from a 3rd-party class that uses a different naming convention (eg. wxPython uses CamelCase method names).  In that case you must follow the same style as the 3rd-party class (assuming it is consistent of course ;^).
-coding standard makes all the developers follow set of guidelines, which in turn will formulate the code, which will let other developers easily understand the code and also let us maintain the code with enhanced effeciency
-locals() and globals() are symbol tables(which will return dictionaries) which will store the symbol tables(a data structure maintaned by compiler,which contains all necessary information about the program) which inturn will store the local variables (information related to local scope)and global variables(functions or variables which are not associated with any class or function) information
-arbitary arguments will be passed as a tuple, whereas with arbitary key word arguments the arguments are passed inside a dictionary
	arbitary arguments:
		def arb_arg(arg1,*arg2):
			print(type(arg2))#it is passed as tuple here
	kwargs ex:
		def myFun(**kwargs):
			for key, value in kwargs.items():#here kwargs is a dictionary
				print ("%s == %s" %(key, value))
		 
		# Driver code
		myFun(first ='Geeks', mid ='for', last='Geeks')  
	for arbitrary arguments and arbitrary kwargs, these are to be used when there is a necessity and no other clear and easy construct is there to fulfill the need
- in python no properties are considered private, but there is a convention to have double underscore before a variable or a method to convey that it is private. a private method or variable can not be accessed outside the class,private variables and private methods are acessed by only public and protected methods inside the class.
-The main convention for private properties and implementation details is to prefix all “internals” with an underscore. If the client code breaks this rule and accesses these marked elements, any misbehavior or problems encountered if the code is modified is the responsibility of the client code.any method or property that is not intended to be used by client code should be prefixed with an underscores
-
filename = 'foobar.hi.txt'
basename, __, ext = filename.split('.')
	Note
	Many Python style guides recommend the use of a single underscore “_” for throwaway variables rather than the double underscore “__” recommended here. The issue is that “_” is commonly used as an alias for the gettext() function, and is also used at the interactive prompt to hold the value of the last operation. Using a double underscore instead is just as clear and almost as convenient, and eliminates the risk of accidentally interfering with either of these other use cases.
-it is often a good idea to use sets or dictionaries instead of lists in cases where:
	The collection will contain a large number of items
	You will be repeatedly searching for items in the collection
	You do not have duplicate items.
  for smaller collections or collections for which you do not perform frequent searching, it is prefered to use lists, as it is memory used to setup hash table is greater than the time saved by improved search speed
-generator expressions (http://docs.python.org/tutorial/classes.html#generator-expressions) are similar to list comprehensions, except that list comprehensions store the list values, whereas generator expressions does not, they just yield the results, it does not return value, it creates a generator object.
note the example below:
	def make_batches(items, batch_size):
		"""
		>>> list(make_batches([1, 2, 3, 4, 5], batch_size=3))
		[[1, 2, 3], [4, 5]]
		"""
		current_batch = []
		for item in items:
			current_batch.append(item)
			if len(current_batch) == batch_size:
				yield current_batch
				current_batch = []
		yield current_batch
-Never remove items from a list while you are iterating through it.Use a list comprehension or generator expression
-when you are assigning a list named a to a variable b and then if you want to make some changes in the list a, those changes will also reflect in b to avoid that, you need to 
	1:use deepcopy method while assigning
	2:use list comprehension if you are operating on all the litems in list based on some conditions
-Use the with open syntax to read from files. This will automatically close files for you, even if an exception is raised in the block.
	with open(log.txt) as f:
		for line in f:
		print(line)
	note: the above block is called with block
-when a logical line of code is longer than the expected limit, then the lines can be seperated by back slash '\', but it is FRAGILE BECAUSE ANY SPACE AFTER THE BACK SLASH WILL RAISE UNEXPECTED RESULTS.A better solution is to use parentheses around your elements. Left with an unclosed parenthesis on an end-of-line, the Python interpreter will join the next line until the parentheses are closed. The same behavior holds for curly and square braces.
ex:
	my_very_big_string = (
		"For a long time I used to go to bed early. Sometimes, "
		"when I had put out my candle, my eyes would close so quickly "
		"that I had not even time to say “I’m going to sleep.”"
	)

	from some.deep.module.inside.a.module import (
		a_nice_function, another_nice_function, yet_another_nice_function)
-Spaces are the preferred indentation method		
-max length of a line in python is suggested as 79, whereas flowing long blocks of text with minimum structural restrictions (doc strings and comments) line length is confined to 72 characters
-Should a line break before or after a binary operator?
	method1:
		# No: operators sit far away from their operands
		income = (gross_wages +
				  taxable_interest +
				  (dividends - qualified_dividends) -
				  ira_deduction -
				  student_loan_interest)
	method2:
		# Yes: easy to match operators with operands
		income = (gross_wages
				  + taxable_interest
				  + (dividends - qualified_dividends)
				  - ira_deduction
				  - student_loan_interest)
    method 2 is prefered as it is more clear					
-when to use Blank Lines?
	Surround top-level function and class definitions with two blank lines.
	Method definitions inside a class are surrounded by a single blank line.
	Extra blank lines may be used (sparingly) to separate groups of related functions. Blank lines may be omitted between a bunch of related one-liners (e.g. a set of dummy implementations).
-Code in the core Python distribution should always use UTF-8 (or ASCII in Python 2).
Files using ASCII (in Python 2) or UTF-8 (in Python 3) should not have an encoding declaration	Use blank lines in functions, sparingly, to indicate logical sections.	
-The function is stateless or a pure function; i.e. it does not have any side-effects (e.g. change some global variable, or change env in any way) and will always return the same output for a given input regardless of when the function is called.
While pure functional style wouldn’t be appropriate, some of the ideas are good to leverage. When possible, favor writing stateless/pure functions. These functions don’t depend on anything other than the input arguments. This makes them easy to reason about and test. This leads to code that is easier to maintain and robust. Lazy computation is another principle that can be used when working with large amounts of data. In Python, generators provide a good way to incorporate the idea of a lazy iterator. Functions are first-class citizens in python and can be passed as an argument to another function just like any other object. This can be leveraged to build generic functions.
A recursive datastructure is used to express the algorithm. Recursion is very frequently used in this style to break down a larger problem into smaller problems which are easily solved. Here we use a list datastructure which has the nice recursive property that a subset of the list is also a list.imagine using a REDUCE to perform sum operation on list)
Object oriented approach may sometime lead to concurrency issue or race conditions, Another way to say the same thing is to suggest using functions and procedures with as few implicit contexts and side-effects as possible. A function’s implicit context is made up of any of the global variables or items in the persistence layer that are accessed from within the function. Side-effects are the changes that a function makes to its implicit context. If a function saves or deletes data in a global variable or in the persistence layer, it is said to have a side-effect.

Carefully isolating functions with context and side-effects from functions with logic (called pure functions) allows the following benefits:

	Pure functions are deterministic: given a fixed input, the output will always be the same.
	Pure functions are much easier to change or replace if they need to be refactored or optimized.
	Pure functions are easier to test with unit tests: There is less need for complex context setup and data cleaning afterwards.
	Pure functions are easier to manipulate, decorate, and pass around.

-the procedural oriented programming paradigm in python is the natural paradigm of python
-ipython is short for interactive python, which is similar to jupyter notebook, which will help write code one line at a time.
- a group of reusable lines are clubbed in to function
  a group of reusable functions(that fall in to a relatable area) are clubbed in to a module
  a group of modules (that make the work related to a particular concept easier) are grouped in to package

-project structure:
	main package or python script,setup.py,requirements.txt should be placed at the root repository
-site-packages- it is the target directory of manually built Python packages. When you build and install Python packages from source (using distutils, probably by executing python setup.py install), you will find the installed modules in site-packages by default
-Makefile
Location->./Makefile
Purpose->Generic management tasks.
If you look at most of my projects or any Pocoo project, you’ll notice a Makefile lying around. Why? These projects aren’t written in C… In short, make is an incredibly useful tool for defining generic tasks for your project.
1-Modules
	Python modules are one of the main abstraction layers available and probably the most natural one. Abstraction layers allow separating code into parts holding related data and functionality.
	To keep in line with the style guide, keep module names short, lowercase, and be sure to avoid using special symbols like the dot (.) or question mark (?). A file name like my.spam.py is the one you should avoid! Naming this way will interfere with the way Python looks for modules.(In the case of my.spam.py Python expects to find a spam.py file in a folder named my which is not the case)
	the import modu statement will look for the proper file, which is modu.py in the same directory as the caller, if it exists. If it is not found, the Python interpreter will search for modu.py in the “path” recursively and raise an ImportError exception when it is not found.
	When modu.py is found, the Python interpreter will execute the module in an isolated scope. Any top-level statement in modu.py will be executed, including other imports if any. Function and class definitions are stored in the module’s dictionary
	In many languages, an include file directive is used by the preprocessor to take all code found in the file and ‘copy’ it into the caller’s code. It is different in Python: the included code is isolated in a module namespace, which means that you generally don’t have to worry that the included code could have unwanted effects, e.g. override an existing function with the same name.(this is why the following import statement: from modu import *.  is generally considered bad practice. Using import * makes the code harder to read and makes dependencies less compartmentalized.)
namepsace-A namespace is a collection of currently defined symbolic names along with information about the object that each name references. You can think of a namespace as a dictionary in which the keys are the object names and the values are the objects themselves
import scenarios:
	Very bad
		[...]
		from modu import *
		[...]
		x = sqrt(4)  # Is sqrt part of modu? A builtin? Defined above?
	Better
		from modu import sqrt
		[...]
		x = sqrt(4)  # sqrt may be part of modu, if not redefined in between
	Best
		import modu
		[...]
		x = modu.sqrt(4)  # sqrt is visibly part of modu's namespace
	-A file modu.py in the directory pack/ is imported with the statement import pack.modu. This statement will look for __init__.py(this code will be run when the package is imported) file in pack and execute all of its top-level statements. Then it will look for a file named pack/modu.py and execute all of its top-level statements. After these operations, any variable, function, or class defined in modu.py is available in the pack.modu namespace.
	Lastly, a convenient syntax is available for importing deeply nested packages: import very.deep.module as mod. This allows you to use mod in place of the verbose repetition of very.deep.module.
-functions are first-class objects(A first class object is an entity that can be dynamically created, destroyed, passed to a function, returned as a value, and have all the rights as other variables in the programming language have.)
-Decorators:
	The Python language provides a simple yet powerful syntax called ‘decorators’. A decorator is a function or a class that wraps (or decorates) a function or a method. The ‘decorated’ function or method will replace the original ‘undecorated’ function or method. Because functions are first-class objects in Python, this can be done ‘manually’, but using the @decorator syntax is clearer and thus preferred.

	def foo():
		# do something

	def decorator(func):
		# manipulate func
		return func

	foo = decorator(foo)  # Manually decorate

	@decorator
	def bar():
		# Do something
	# bar() is decorated
-Context Managers
	A context manager is a Python object that provides extra contextual information to an action. This extra information takes the form of running a callable upon initiating the context using the with statement, as well as running a callable upon completing all the code inside the with block. The most well known example of using a context manager is shown here, opening on a file:
	with open('file.txt') as f:
		contents = f.read()
	-Python calls __enter__ when execution enters the context of the with statement and it's time to acquire the resource. When execution leaves the context again, Python calls __exit__ to free up the resource. Writing a class-based context manager isn't the only way to support the with statement in Python, observe the below example
	class CustomOpen(object):
		def __init__(self, filename):
			self.file = open(filename)

		def __enter__(self):
			return self.file

		def __exit__(self, ctx_type, ctx_value, ctx_traceback):
        self.file.close()

	with CustomOpen('file') as f:
		contents = f.read()
	expl:
	This is just a regular Python object with two extra methods that are used by the with statement. CustomOpen is first instantiated and then its __enter__ method is called and whatever __enter__ returns is assigned to f in the as f part of the statement. When the contents of the with block is finished executing, the __exit__ method is then called.
- str, int, long, bool, float, tuple are all immutable datatypes in python
-using join() is not always best. In the instances where you are creating a new string from a pre-determined number of strings, using the addition operator is actually faster. But in cases like above or in cases where you are adding to an existing string, using join() should be your preferred method.
-Modules
	A python “module” is a single namespace, with a collection of values:
			functions
			constants
			class definitions
			really any old value.
	A module usually corresponds to a single file: something.py
-Packages
	A “package” is essentially a module, except it can have other modules (and indeed other packages) inside it.
	A package usually corresponds to a directory with a file in it called __init__.py and any number of python files or other package directories:
		a_package
		   __init__.py
		   module_a.py
		   a_sub_package
			 __init__.py
			 module_b.py
- a package should definetly have setup.py so that it can have metadeta about the package and the metadata is as follows:
	Version & package metadata
	List of packages to include
	List of other files to include
	List of dependencies
	List of extensions to be compiled
	
- to get all the dependencies or to export the environment to a yml file use:
	conda env export > <path of the file where you want to store dependencies (most probably an env.yml or environment.yml)>
- import os
 os.makedirs(<directory path>, exist_ok=True) #this will create a directory if the path is not exist and it will not raise an exception because of exist_ok =True, if it is false, it will raise an error.
 
-after creating a package,you have to navigate to the folder, fill setup.py details then run the following commandd
 pip install -e .
python setup.py sdist bdist_wheel(generates the .whl file in dist folder in current directory, this is the installable that will be used when you want to install packages)
pip install <whl file path that ends with .whl>(Install the .whl file generated in above step which will be in dist folder)

-python3 -m pip install -U <list of packages you want to install which will be seperated by a space>
example:
python3 -m pip install -U jupyter matplotlib numpy pandas scipy scikit-learn

to install virtual environments using pip:(again, if you want virtualenv to be installed for all users on your machine, remove --user and run this command with administrator rights)
	python3 -m pip install --user -U virtualenv
-- as we do virtual environments in conda, we can also do it in normal python using commands
-describe() method in pandas ignores null values i.e, if there are 30 fields and 10 fields are null's then it will take 20 in to consideration not 30 to calculate mean,count,average and so on...
-hist() method on the whole dataset (as shown in the following code example), and it will plot a histogram for each numerical attribute
code:
	%matplotlib inline
	import matplotlib.pyplot as plt
	housing.hist(bins=50, figsize=(20,15))
	plt.show()
-explanation for %matplotlib inline:
	The hist() method relies on Matplotlib, which in turn relies on a user-specified graphical backend to draw on your screen. So before you can plot anything, you need to specify which backend Matplotlib should use. The simplest option is to use Jupyter’s magic command %matplotlib inline. This tells Jupyter to set up Matplotlib so it uses Jupyter’s own backend. Plots are then rendered within the notebook itself. Note that calling show() is optional in a Jupyter notebook, as Jupyter will automatically display plots when a cell is executed.
-df.drop([column or list of columns])#will not remove the columns and just assigns them or returns them and columns will only be removed when you use inplace=True
-check out the notes in this link(https://docs.python.org/3/howto/argparse.html) and add points to argparse when free.
-list(df) will give the column names list 
--argparse
import argparse #this module helps in having better features to pass argument

parser = argparse.ArgumentParser() 
parser.add_argument("echo", help="echo the string you use here") #help messages are displayed in detail if you use python <scriptname.py> -h (h here stands for help,) echo is the variable to which the parameter1 is assigned
parser.add_argument("echo1", help="echo1 the string you use here")
args = parser.parse_args()
print(args)

execution:
<scriptname.py> hi there #this for above example will be as echo='hi', echo1='there'
by default all the arguments are treated as strings, if you want to treat the parameter as int you have to explicilty specify it like below.
parser.add_argument("num1", help="this is the first argument", type=int)
parser.add_argument("num2", help="this is the second argument", type=int)

abc.py 4 6
-verbose in argparse
	import argparse
	parser = argparse.ArgumentParser()
	parser.add_argument("--verbosity", help="increase output verbosity")
	args = parser.parse_args()
	if args.verbosity:
		print("verbosity turned on")
And the output:

	$ python3 prog.py --verbosity 1
	verbosity turned on
	$ python3 prog.py
	$ python3 prog.py --help
	usage: prog.py [-h] [--verbosity VERBOSITY]

	options:
	  -h, --help            show this help message and exit
	  --verbosity VERBOSITY
							increase output verbosity
	$ python3 prog.py --verbosity
	usage: prog.py [-h] [--verbosity VERBOSITY]
	prog.py: error: argument --verbosity: expected one argument
Here is what is happening:
The program is written so as to display something when --verbosity is specified and display nothing when not.
To show that the option is actually optional, there is no error when running the program without it. Note that by default, if an optional argument isn’t used, the relevant variable, in this case args.verbosity, is given None as a value, which is the reason it fails the truth test of the if statement.
The help message is a bit different.
When using the --verbosity option, one must also specify some value, any value.

but for our simple program, only two values are actually useful, True or False. Let’s modify the code accordingly:

	import argparse
	parser = argparse.ArgumentParser()
	parser.add_argument("--verbose", help="increase output verbosity",
						action="store_true")#notice we used verbose, not verbosity like we have used in above example
	#if you use parser.add_argument("-v", "--verbose", help="increase output verbosity",
                    action="store_true") instead of above line, -v can be used as shortcut while executing code you can give 
					python3 <script address.py> -v, it will turn verbosity on
	args = parser.parse_args()
	if args.verbose:#notice we used verbose, not verbosity like we have used in above example
		print("verbosity turned on")
And the output:
	
	$ python3 prog.py --verbose #notice that we passed verbose not verbosity, if we dont pass any value along with it, it is taken as true, there by the above loop executes, if you don't pass --verbose while running it will be passed as false and it will not execute if loop above, and wont raise an error
	verbosity turned on
	$ python3 prog.py --verbose 1
	usage: prog.py [-h] [--verbose]
	prog.py: error: unrecognized arguments: 1
	$ python3 prog.py --help
	usage: prog.py [-h] [--verbose]

	options:
	  -h, --help  show this help message and exit
	  --verbose   increase output verbosity
Here is what is happening:

The option is now more of a flag than something that requires a value. We even changed the name of the option to match that idea. Note that we now specify a new keyword, action, and give it the value "store_true". This means that, if the option is specified, assign the value True to args.verbose. Not specifying it implies False.

It complains when you specify a value, in true spirit of what flags actually are.

Notice the different help text.
-you can combine both positional and optional arguments to have the functionality of verbosity to some good use:

	import argparse
	parser = argparse.ArgumentParser()
	parser.add_argument("square", type=int,
						help="display a square of a given number")
	parser.add_argument("-v", "--verbose", action="store_true",
						help="increase output verbosity")
	args = parser.parse_args()
	answer = args.square**2
	if args.verbose:
		print(f"the square of {args.square} equals {answer}")
	else:
		print(answer)
terminal:
	$ python3 prog.py
	usage: prog.py [-h] [-v] square
	prog.py: error: the following arguments are required: square
	$ python3 prog.py 4
	16
	$ python3 prog.py 4 --verbose #note:here we passed 4 first and --verbose next, it worked properly
	the square of 4 equals 16
	$ python3 prog.py --verbose 4 #note:here we passed --verbose first and 4 next, it worked properly, the position does not matter
	the square of 4 equals 16
	
-we can also have multiple verbosity values as well:
code:
	import argparse
	parser = argparse.ArgumentParser()
	parser.add_argument("square", type=int,
						help="display a square of a given number")
	parser.add_argument("-v", "--verbosity", type=int,
						help="increase output verbosity")
	#for above line, it accepts any number as parameter alongside verbosity, $ python3 prog.py 4 -v 3 is valid(else loop also executes), $ python3 prog.py 4 -v 1000000 is also valid(else loop also executes), if you want to restrict verbosity values to a range use the below line of code
	#parser.add_argument("-v", "--verbosity", type=int, choices=[0, 1, 2],
                    help="increase output verbosity") #this will only accept 0,1,2 as values, any other value will get an error, this is more interactive and is displayed when you use -h or if you throw a wrong error
	#parser.add_argument("-v", "--verbosity", action="count",
                    help="increase output verbosity") #when you use parameter action = count and if you want to pass verbose value as 2, then $ python3 prog.py 4 -v 2 will raise an error, you have to give $ python3 prog.py 4 -vv  or 
					$ python3 prog.py 4 --verbosity --verbosity (as it will count the option as the verbose parameter you want to pass) #if you don’t specify the -v flag, that flag is considered to have None value.
	parser.add_argument("-v", "--verbosity", action="count", default=0,
                    help="increase output verbosity") #as said in above line of code, you can have None, you cant compare it with int so you can assign a default value
	args = parser.parse_args()
	answer = args.square**2
	if args.verbosity == 2:
		print(f"the square of {args.square} equals {answer}")
	elif args.verbosity == 1:
		print(f"{args.square}^2 == {answer}")
	else:
		print(answer)
-Notice that so far we’ve been using verbosity level to change the text that gets displayed. The following example instead uses verbosity level to display more text instead:

	import argparse
	parser = argparse.ArgumentParser()
	parser.add_argument("x", type=int, help="the base")
	parser.add_argument("y", type=int, help="the exponent")
	parser.add_argument("-v", "--verbosity", action="count", default=0)
	args = parser.parse_args()
	answer = args.x**args.y
	if args.verbosity >= 2:
		print(f"Running '{__file__}'")
	if args.verbosity >= 1:
		print(f"{args.x}^{args.y} == ", end="")
	print(answer)
Output:
	$ python3 prog.py 4 2
	16
	$ python3 prog.py 4 2 -v
	4^2 == 16
	$ python3 prog.py 4 2 -vv
	Running 'prog.py'
	4^2 == 16
-Conflicting options
So far, we have been working with two methods of an argparse.ArgumentParser instance. Let’s introduce a third one, add_mutually_exclusive_group(). It allows for us to specify options that conflict with each other. Let’s also change the rest of the program so that the new functionality makes more sense: we’ll introduce the --quiet option, which will be the opposite of the --verbose one:

	import argparse

	parser = argparse.ArgumentParser()
	group = parser.add_mutually_exclusive_group()
	group.add_argument("-v", "--verbose", action="store_true")
	group.add_argument("-q", "--quiet", action="store_true")
	parser.add_argument("x", type=int, help="the base")
	parser.add_argument("y", type=int, help="the exponent")
	args = parser.parse_args()
	answer = args.x**args.y

	if args.quiet:
		print(answer)
	elif args.verbose:
		print(f"{args.x} to the power {args.y} equals {answer}")
	else:
		print(f"{args.x}^{args.y} == {answer}")
Our program is now simpler, and we’ve lost some functionality for the sake of demonstration. Anyways, here’s the output:
output:
	$ python3 prog.py 4 2
	4^2 == 16
	$ python3 prog.py 4 2 -q
	16
	$ python3 prog.py 4 2 -v
	4 to the power 2 equals 16
	$ python3 prog.py 4 2 -vq
	usage: prog.py [-h] [-v | -q] x y
	prog.py: error: argument -q/--quiet: not allowed with argument -v/--verbose
	$ python3 prog.py 4 2 -v --quiet
	usage: prog.py [-h] [-v | -q] x y
	prog.py: error: argument -q/--quiet: not allowed with argument -v/--verbose
That should be easy to follow. I’ve added that last output so you can see the sort of flexibility you get, i.e. mixing long form options with short form ones.

Before we conclude, you probably want to tell your users the main purpose of your program, just in case they don’t know:

	import argparse

	parser = argparse.ArgumentParser(description="calculate X to the power of Y")#NOTE: you can add description to an argparse object, that is visible when you use -h with python3 <script.py> [-h |--help]
	group = parser.add_mutually_exclusive_group()
	group.add_argument("-v", "--verbose", action="store_true")
	group.add_argument("-q", "--quiet", action="store_true")
	parser.add_argument("x", type=int, help="the base")
	parser.add_argument("y", type=int, help="the exponent")
	args = parser.parse_args()
	answer = args.x**args.y

	if args.quiet:
		print(answer)
	elif args.verbose:
		print("{} to the power {} equals {}".format(args.x, args.y, answer))
	else:
    print("{}^{} == {}".format(args.x, args.y, answer))
Note that slight difference in the usage text. Note the [-v | -q], which tells us that we can either use -v or -q, but not both at the same time:

	$ python3 prog.py --help
	usage: prog.py [-h] [-v | -q] x y

	calculate X to the power of Y

	positional arguments:
	  x              the base
	  y              the exponent

	options:
	  -h, --help     show this help message and exit
	  -v, --verbose
	  -q, --quiet
-- one python script can have more than one main function
--when you want to add an optional argument through argparse, you have to use:
	parser.add_argument("--dataset_path", help="path of the dataset")#notice the -- before the parameter, that is what makes the argument optional
	
	while running the script if you want to pass value, you can use:
		python3 <script path> --dataset_path 'src/data'
	if you dont want to pass you can simply pass:
		python3 <script path> 
--imputer will take existing values in consideration while applying the strategy.
ex: l=[1,2,nan]
if we apply mean strategy using imputer, then mean(1,2) is calculated and imputed in place of nan
the list will be =[1,2,1.5]		
		
--let's suppose you are importing a python script named config (which is in the same folder), you can import it in 2 ways:
	1: use import statement as
		(let say there is a folder in current working directory(folder) named src, inside that folder you have a py file called ingest_data)
		from folder.python_file import classname
		from src.config import Config
		then you have to run as
		python3 -m <path script.file>
		ex:python3 -m src.ingest_data
	2:use import statement as
		from <parent foldername.filename> import <class name>
		then you have to run as
		python3 <parent folder.>
--pd.get_dummies work in favour of text columns similar to one hot encoding
	drop_first=True this will remove one column out of n columns so that if n-1 columns are 0, then it means the removed column value will supposedly be 1
-- if you want to downgrade to a lower version of python in an environment in conda, you can use normal conda install command
	conda install python=<version>
-- you have to install jupyter notebook using command 
	conda install jupyter
	you can launch ipython in wsl by just typing the "ipython" in wsl
	similarly if you want to launch jupyter notebook , just type "jupyter notebook" in wsl, and you will get one (or more) file links and one (or more) URL's
	if you copy paste anyone of above url or file, it should launch wsl's jupyter notebook
	conda install jupyter-lab #this will install jupyter lab which is more comfortable type of working mode
	in ipython:
	?- this will give shorthand for accessing this documentation and other relevant information
		In [3]: len?
		Signature: len(obj, /)
		Docstring: Return the number of items in a container.
		Type:      builtin_function_or_method

		In [4]: len??
		Signature: len(obj, /)
		Docstring: Return the number of items in a container.
		Type:      builtin_function_or_method

		In [5]: l=[1,2,3]

		In [6]: l.insert?
		Signature: l.insert(index, object, /)
		Docstring: Insert object before index.
		Type:      builtin_function_or_method

		In [7]: l?
		Type:        list
		String form: [1, 2, 3]
		Length:      3
		Docstring:
		Built-in mutable sequence.
	??- this will give the source code for functions
	If you play with this much, you'll notice that sometimes the ?? suffix doesn't display any source code: this is generally because the object in question is not implemented in Python, but in C or some other compiled extension language. If this is the case, the ?? suffix gives the same output as the ? suffix. ?len and ??len will have same output
	by pressing <tab> anywhere of python code will give you the possible code options that are inline with the operations that can be performed at that point
-Beyond tab completion: wildcard matching
	Tab completion is useful if you know the first few characters of the object or attribute you're looking for, but is little help if you'd like to match characters at the middle or end of the word. For this use-case, IPython provides a means of wildcard matching for names using the * character.

	For example, WE CAN USE THIS TO LIST EVERY OBJECT IN THE NAMESPACE that ends with Warning:

	In [10]: *Warning?
	BytesWarning                  RuntimeWarning
	DeprecationWarning            SyntaxWarning
	FutureWarning                 UnicodeWarning
	ImportWarning                 UserWarning
	PendingDeprecationWarning     Warning
	ResourceWarning
-new shortcuts in ipython terminal:(some of them work in vs code terminal as well)
	Ctrl-r	Reverse-search through command history
	Ctrl-d	Delete next character in line
	Ctrl-k	Cut text from cursor to end of line
	Ctrl-u	Cut text from beginning of line to cursor
	Ctrl-y	Yank (i.e. paste) text that was previously cut
	Ctrl-t	Transpose (i.e., switch) previous two characters
	Ctrl-a	Move cursor to the beginning of the line
	Ctrl-e	Move cursor to the end of the line
	Ctrl-l	Clear terminal screen
	Ctrl-c	Interrupt current Python command
	Ctrl-d	Exit IPython session
-%run <script.py>	
	will let the script run in ipython, and the methods are available to be called all along the session
-Another example of a useful magic function is %timeit, which will automatically determine the execution time of the single-line Python statement that follows it.1
-PASSING VALUES TO AND FROM THE SHELL
Shell Commands in IPython
Any command that works at the command-line can be used in IPython by prefixing it with the ! character. For example, the ls, pwd, and echo commands can be run as follows
	In [1]: !ls
	myproject.txt

	In [2]: !pwd
	/home/jake/projects/myproject

	In [3]: !echo "printing from the shell"
	printing from the shell
Besides %cd, other available shell-like magic functions are %cat, %cp, %env, %ls, %man, %mkdir, %more, %mv, %pwd, %rm, and %rmdir, any of which can be used without the % sign if automagic is on. 
THIS ACCESS TO THE SHELL FROM WITHIN THE SAME TERMINAL WINDOW AS YOUR PYTHON SESSION MEANS THAT THERE IS A LOT LESS SWITCHING BACK AND FORTH BETWEEN INTERPRETER AND SHELL AS YOU WRITE YOUR PYTHON CODE.